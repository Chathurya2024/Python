{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0281a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def get_arxiv_metadata(category, start_year, end_year):\n",
    "    base_url = 'http://export.arxiv.org/api/query'\n",
    "     #stores the base URL of the ArXiv API\n",
    "    query = f\"cat:{category} AND submittedDate:[{start_year}0101 TO {end_year}1231]\"\n",
    "    #The search query for the API request, filters by category and date range.\n",
    "    params = {'search_query': query, 'max_results': 1000}\n",
    "    response = requests.get(base_url, params=params)\n",
    "    return response.text\n",
    "\n",
    "def extract_metadata(xml_data, year):\n",
    "    # Function to extract metadata from XML data\n",
    "    metadata = [] #creating an empty list\n",
    "    root = ET.fromstring(xml_data)\n",
    "    for i, entry in enumerate(root.findall('{http://www.w3.org/2005/Atom}entry'), start=1):\n",
    "        # Looping over each <entry> element in the XML\n",
    "        entry_metadata = {}\n",
    "        # Dictionary to store metadata for each entry\n",
    "        entry_metadata['title'] = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        # Extracting the title and doing the same for the rest of the fields\n",
    "        entry_metadata['authors'] = [author.text for author in entry.findall('.//{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')]\n",
    "        entry_metadata['summary'] = entry.find('.//{http://www.w3.org/2005/Atom}summary').text\n",
    "        entry_metadata['year'] = year\n",
    "        entry_metadata['entry_id'] = entry.find('{http://www.w3.org/2005/Atom}id').text\n",
    "        entry_metadata['updated'] = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        entry_metadata['published'] = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        entry_metadata['primary_category'] = entry.find('{http://www.w3.org/2005/Atom}category[@scheme=\"http://arxiv.org/schemas/atom\"]').attrib['term']\n",
    "        entry_metadata['links'] = entry.find('{http://www.w3.org/2005/Atom}link[@title=\"pdf\"]').attrib['href']\n",
    "        \n",
    "        metadata.append(entry_metadata)\n",
    "        # Appending the entry metadata to the list\n",
    "    return metadata\n",
    "\n",
    "def store_metadata(metadata, output_file):\n",
    "    # Function to store metadata in a CSV file\n",
    "    df = pd.DataFrame(metadata)\n",
    "    # Creating a DataFrame from the metadata\n",
    "    df.to_csv(output_file, index=False)\n",
    "    # Saving the DataFrame as a CSV file\n",
    "    \n",
    "categories = ['cs.DB', 'cs.GR', 'cs.RO', 'cs.ET']\n",
    "start_year = 2018\n",
    "end_year = 2022\n",
    "\n",
    "all_metadata = []\n",
    "# Empty list to store all metadata\n",
    "for category in categories:\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        xml_data = get_arxiv_metadata(category, year, year)\n",
    "        metadata = extract_metadata(xml_data, year)\n",
    "        all_metadata.extend(metadata)\n",
    "\n",
    "output_file = 'papers.csv'\n",
    "store_metadata(all_metadata, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd0d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
